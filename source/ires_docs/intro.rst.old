.. highlight:: rst

Introduction
============

Overview
--------
The demand for near-real-time, data-driven analytics has given rise to diverse execution engines and data stores that target specific data and computation types. Many of these systems  are  now  offered  as  a  service  by  IaaS  providers,  enabling  a  very  wide deployment range. There also exist approaches in the literature that manage to optimize their performance (e.g.,  [1]  [2] ) by automatically tuning a number of configuration parameters. Yet, these schemes assume strictly single-engine  environments (mainly the Hadoop  ecosystem),  thus  considering  specific  data  formats  and  query/analytics  task types. However,  modern  workflows  have  become  increasingly long  and  complex  and  may include  multiple  operators,  ranging  from  simple  Select-Project-Join  (SPJ)  to  complex Machine Learning (ML) or custom operators  that operate on diverse data types (e.g., relational,  key-value,  graph,  etc.)  generated  from different  resources.  What  is  more, analysts need to be able to execute them under varying constraints and policies (e.g., optimize  performance  or  cost,  require  different  fault-tolerance  degrees,  etc.).  There currently exists no single platform that can optimize for this complexity [3] .  Sensing this trend, cloud software companies now offer software distributions in pre-cooked VM images or as a service. These distributions incorporate different processing frameworks, data stores and libraries to alleviate the burden of multiple installations and configurations (e.g., [4]  [5]  [6]  [7] ). Yet, such multi-engine environments lack a meta-scheduler that could automatically match tasks to the right engine(s) according to multiple criteria, deploy and run them without manual intervention.  To address multi-engine analytics workflow optimization we designed and developed the  Intelligent  Multi-Engine  Resource  Scheduler  (IReS),  an  integrated,  open  source platform for managing, executing and monitoring complex analytics workflows. IReS is a core  component  of  the  ASAP  system  architecture  and its  main  task  is  to  "mix-and-match" diverse execution engines and data stores in order to optimize a workflow with respect to multiple, user-defined criteria  [3] . To that end, IReS incorporates a modeling framework that constantly evaluates the cost and  performance  of  data  and  computational  resources  under  various  configuration setups  in  order  to  decide  on  the  most  advantageous store,  indexing  and  execution pattern. A tree-based metadata language that describes operators in abstract and instantiated forms enables the search and matching of operators that perform a similar task in the planning  phase.  Afterwards,  a  decision  making  module  chooses  among  the  different equivalent execution plans (i.e., on different engines, resulting in equivalent output) the one that best fits the given policy based on cost and performance models. The chosen plan is scheduled and enforced, taking into account the available resources.

References
-----------
1. Herodotou,  H.    et  al.  Starfish:  A  Self-tuning  System  for  Big  Data  Analytics.  In  CIDR, 2011. 
2. Lim,  H.,  Herodotou,  H.  and  Babu,  S.  Stubby:  A  Transformation-based  Optimizer  for Mapreduce Workflows. VLDB, 2012. 
3. Tsoumakos,   D.   and   Mantas,   C.   The   Case   for   Multi-engine   Data   Analytics.   In Proceedings  of  the  2013  Workshop  on  Middleware  for HPC  and  Big  Data  Systems (MHPC'13, part of Euro-Par 2013), Aachen, Germany, August 27, 2013.
4. Cloudera Distribution CDH 5.2.0.  http://www.cloudera.com/content/cloudera/en/downloads/cdh/cdh-5-2-0.html.
5. Heroku add-ons. https://addons.heroku.com/.
6. Hortonworks Sandbox 2.1.  http://hortonworks.com/products/hortonworks-sandbox/. 
7. Running Databases on AWS. http://aws.amazon.com/running_databases/