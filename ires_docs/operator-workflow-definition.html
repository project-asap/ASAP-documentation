<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Workflow and Operator Definition &#8212; Asap 0.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Extension of the Apache Spark" href="../spark.html" />
    <link rel="prev" title="REST API" href="rest.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="workflow-and-operator-definition">
<h1>Workflow and Operator Definition<a class="headerlink" href="#workflow-and-operator-definition" title="Permalink to this headline">¶</a></h1>
<div class="section" id="tree-metadata-framework">
<h2>Tree-metadata framework<a class="headerlink" href="#tree-metadata-framework" title="Permalink to this headline">¶</a></h2>
<p>The metadata framework describes data and operators. Data and operators can be either abstract or materialized. Abstract are the operators and datasets that are described partially or at a high level by the user when composing her workflow whereas materialized  are  the  actual  operator  implementations  and  existing  datasets,  either provided by the user or residing in a repository. Both data and operators need to be accompanied by a set of metadata, i.e., properties that  describe  them.  Such  properties  include  input  data  types  and  parameters  of operators,  location  of  data  objects  or  operator  invocation  scripts,  data  schemata, implementation details, engines etc. The provided metadata can be used to:</p>
<ol class="loweralpha simple">
<li>Match abstract operators to materialized ones</li>
<li>Check the usability of a dataset as input for an operator. If the dataset does not match the operator’s input, its metadata can be also used to check for appropriate transform/move operators that can be applied.</li>
<li>Provide  optimization  parameters  like  the  profiling input/output  space  (the parameters to take into account and the metrics to measure respectively) or user provided  profile  functions.  This  information  is  based  on  our  black  box  operator profiling approach.</li>
<li>Provide  execution  parameters  like  the  path  of  a  file  in  the  filesystem  or arguments for the execution of the operator script.To  provide  such  a  user  extensible  metadata  framework  we  opt  for  a  generic  tree metadata format. To avoid restricting the user and allow for extensibility, the first levels of the metadata tree are predefined but users can add their ad-hoc subtrees to define their custom data or operators. Moreover, some fields (mostly the ones related to the operator and data requirements) are compulsory while the rest are optional and user defined. Materialized data and operators need to have all their compulsory fields filled in with information. Abstract data and operators do not adhere to this rule. In general we define the following predefined parts of the meta-data tree</li>
</ol>
<div class="section" id="constraints">
<h3>Constraints<a class="headerlink" href="#constraints" title="Permalink to this headline">¶</a></h3>
<p>This sub-tree contains all the meta-data information that is used to match abstract and materialized operators and datasets. The information contained in this sub-tree should contain  input/output  specification  for  operators,  algorithm,  engine  specification  and whatever  else  the  user  considers  that  should  take  part  in  the  abstract/materialized matching of operators. The predefined, compulsory fields of the operator metadata are primarily the number of its inputs and outputs:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="o">.</span><span class="n">number</span><span class="o">=&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">inputs</span><span class="o">&gt;</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="o">.</span><span class="n">number</span><span class="o">=&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">outputs</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>In the above description, the metadata were presented with a key-value representation were the key denotes the path from the root node of the tree to the specified metadata leaf. For each defined input and output the respective specification metadata should be put in the following subtrees:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="p">{</span><span class="nb">id</span><span class="p">}</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="p">{</span><span class="nb">id</span><span class="p">}</span>
</pre></div>
</div>
<p>The respective metadata subtrees are automatically matched with the existing datasets in order to check for usability or move/transform operators that should be applied. The respective  output  metadata  specifications  are  also copied  to  the  metadata  of  the intermediate output workflow datasets in order to enforce data constraints along the workflow.</p>
</div>
<div class="section" id="execution">
<h3>Execution<a class="headerlink" href="#execution" title="Permalink to this headline">¶</a></h3>
<p>This subtree contains all the information required for the execution of a materialized operator.  Our execution engine utilizes YARN in order  to  execute  a  DAG  graph  of  operators.  Execution  specific  metadata  like  dataset
paths or details about staging in/out files from containers that use their local file system are provided here.  This subtree has the following predefined metadata for datasets:</p>
<p>Execution.path=&lt;the path of the dataset&gt;</p>
<p>For operators we have the following metadata:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">Execution</span><span class="o">.</span><span class="n">LuaScript</span><span class="o">=&lt;</span><span class="n">Lua</span> <span class="n">script</span> <span class="n">of</span> <span class="n">the</span> <span class="n">operator</span><span class="o">&gt;</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">Arguments</span><span class="o">.</span><span class="n">number</span><span class="o">=&lt;</span><span class="n">number</span> <span class="n">of</span> <span class="n">arguments</span> <span class="n">of</span> <span class="n">the</span> <span class="n">execution</span> <span class="n">script</span><span class="o">&gt;</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">Argument</span><span class="p">{</span><span class="nb">id</span><span class="p">}</span><span class="o">=&lt;</span><span class="n">value</span> <span class="n">of</span> <span class="n">the</span> <span class="n">specific</span> <span class="n">argument</span><span class="o">&gt;</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">Output</span><span class="p">{</span><span class="nb">id</span><span class="p">}</span><span class="o">.</span><span class="n">path</span><span class="o">=&lt;</span><span class="n">the</span> <span class="n">path</span> <span class="n">of</span> <span class="n">the</span> <span class="n">specific</span> <span class="n">output</span> <span class="n">dataset</span><span class="o">&gt;</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">copyToLocal</span><span class="o">=&lt;</span><span class="nb">list</span>  <span class="n">of</span>  <span class="n">files</span>  <span class="n">that</span>  <span class="n">need</span>  <span class="n">to</span>  <span class="n">be</span>  <span class="n">copied</span>  <span class="ow">in</span>  <span class="n">the</span>  <span class="n">container</span>  <span class="n">before</span>  <span class="n">the</span> <span class="n">execution</span> <span class="n">of</span> <span class="n">the</span> <span class="n">operator</span><span class="o">&gt;</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">copyFromLocal</span><span class="o">=&lt;</span><span class="nb">list</span> <span class="n">of</span> <span class="n">files</span> <span class="n">that</span> <span class="n">need</span> <span class="n">to</span> <span class="n">be</span> <span class="n">maintained</span> <span class="n">after</span> <span class="n">the</span> <span class="n">execution</span> <span class="n">of</span> <span class="n">the</span> <span class="n">operator</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>The  use  of  those  metadata  is  further  described  in  the Enforcer section. In  general,  these  metadata  give  information  about  the location of execution script for the operator as well as for its arguments. We also give information  about  stage  in  and  stage  out  files  that  are  required  by  the  distributed execution of operators using YARN containers.</p>
</div>
<div class="section" id="optimization">
<h3>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h3>
<p>This part of the metadata gives information required by the profiler module. They are used  to  effectively  estimate  the  execution  metrics of  operators  and  utilize  them  to generate execution plans for workflows.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">Optimization</span><span class="o">.</span><span class="n">inputSpace</span><span class="o">.</span><span class="p">{</span><span class="n">metric</span> <span class="n">name</span><span class="p">}</span><span class="o">=&lt;</span><span class="nb">type</span><span class="o">&gt;</span>
<span class="n">Optimization</span><span class="o">.</span><span class="n">outputSpace</span><span class="o">.</span><span class="p">{</span><span class="n">metric</span> <span class="n">name</span><span class="p">}</span><span class="o">=&lt;</span><span class="nb">type</span><span class="o">&gt;</span>
<span class="n">Optimization</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="p">{</span><span class="n">metric</span> <span class="n">name</span><span class="p">}</span><span class="o">=&lt;</span><span class="n">UserFunction</span> <span class="ow">or</span> <span class="n">Profile</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>As can be seen from the above metadata, users are able to define the input/output profiling space for each materialized operator. For each of the output  metrics  the  user  is  able  to  either  provide  a  user  defined  function,  used  for estimation, or state to the system that the metric should be estimated using a profiling procedure.  In the following sections, we give some concrete examples for the metadata of datasets and  operators.  For  better  understanding  we  give  both  a  visual  representation  of  the metadata  tree  as  can  be  seen  from  the  platform’s  web  interface  and  also  the  actual metadata in key-values where the key denotes the path of the specific metadata node.</p>
</div>
<div class="section" id="dataset-metadata-description">
<h3>Dataset metadata description<a class="headerlink" href="#dataset-metadata-description" title="Permalink to this headline">¶</a></h3>
<p>In this section, we give an example of a dataset description (Figure 4).</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">Optimization</span><span class="o">.</span><span class="n">documents</span><span class="o">=</span><span class="mi">2000</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">FS</span><span class="o">=</span><span class="n">HDFS</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">type</span><span class="o">=</span><span class="n">SequenceFile</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">path</span><span class="o">=</span><span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">user</span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">asapDataAll</span>
</pre></div>
</div>
<div class="figure" id="id1">
<img alt="../_images/datasetmeta.png" src="../_images/datasetmeta.png" />
<p class="caption"><span class="caption-text">Dataset Metadata</span></p>
</div>
</div>
<div class="section" id="operator-metadata-description">
<h3>Operator metadata description<a class="headerlink" href="#operator-metadata-description" title="Permalink to this headline">¶</a></h3>
<p>In this section, we give an example of a materialized operator description. We also provide a <a class="reference external" href="./files/description_template">template</a> of an operator description file.</p>
<div class="figure" id="id2">
<img alt="../_images/materializedop.png" src="../_images/materializedop.png" />
<p class="caption"><span class="caption-text">Materialized Operator Description</span></p>
</div>
</div>
<div class="section" id="tree-metadata-matching">
<h3>Tree-metadata matching<a class="headerlink" href="#tree-metadata-matching" title="Permalink to this headline">¶</a></h3>
<p>Apart from materialized operators and datasets the user of the IReS platform can define abstract operators and datasets that are used for creating abstract workflows and can be matched with the existing materialized ones in order to find all possible execution plans. Abstract operators are described using the same tree metadata framework, described in the  previous  sections.  The  main  difference  is  that abstract  operators  can  have  less metadata  attributes  than  the  materialized  ones.  We also  allow  users  to  add  regular expressions in the abstract operator metadata. This is done in order for IReS platform to be able to support more generic matching. For example the * symbol under a field means that the abstract operator can match materialized ones with any value in that field. The matching procedure checks if all the metadata of the abstract operator are present in (match if they are regular expressions) the materialized operator. To make this check efficient,  the  metadata  trees  are  stored  in  main  memory  tree  structures.  The  tree structure used store all children of a metadata node in a sorted list according to their name. Thus, if both metadata trees are stored with ordering we can perform a merge check of both trees in order to find if the operators match. This procedure iterates over the sorted metadata and tries to match the abstract with the materialized ones. To check the  matching  of  two  operators  we  require,  in  worst case,  only  one  pass  over  the metadata  of  both  operators.  Thus,  the  matching  process  is  linear  to  the  size  of  the metadata trees and can be used very efficiently.</p>
</div>
<div class="section" id="abstract-operator-description">
<h3>Abstract operator description<a class="headerlink" href="#abstract-operator-description" title="Permalink to this headline">¶</a></h3>
<p>In this section, we give an example of an abstract operator description (Figure 6).</p>
<p>Abstract operator metadata</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="o">.</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="o">.</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">OpSpecification</span><span class="o">.</span><span class="n">Algorithm</span><span class="o">.</span><span class="n">name</span><span class="o">=</span><span class="n">TF_IDF</span>
</pre></div>
</div>
<p>As  we  can  see,  the  abstract  operator  contains  metadata  only  under  the  constraints subtree because only those are used for the matching procedure. It mainly targets the matching of the algorithmic operation of the operators as well as the matching of inputs and  outputs  used.  This  operator  matches  with  the  materialized  TF_IDF  operator presented in the previous section.</p>
<div class="figure" id="id3">
<img alt="../_images/abstractop.png" src="../_images/abstractop.png" />
<p class="caption"><span class="caption-text">Abstract Operator Description</span></p>
</div>
</div>
<div class="section" id="abstract-workflow-description">
<h3>Abstract workflow description<a class="headerlink" href="#abstract-workflow-description" title="Permalink to this headline">¶</a></h3>
<p>This section describes the definition of an abstract workflow. The user of the IReS platform has the ability to describe a workflow in an abstract way and the let the system find all possible matches for the operators and generate the materialized workflow that contains  all  the  possible  alternative  execution  plans.  An  abstract  workflow  can  be created  using  both  materialized  and  abstract  datasets  and  operators.  Materialized datasets are used to define the already existing input datasets of the workflow. Abstract datasets  can  be  used  for  defining  the  intermediate results  that  are  created  after  the execution of a specific operator. These abstract datasets will get concrete specifications from the materialized operator’s output specifications when the materialized workflow is generated. Concerning operators, the user can create her workflow using materialized operators that exist in the operator library or abstract operators that match with several of the existing materialized operators. An example of an abstract workflow is depicted in Figure 7.</p>
<p>An abstract workflow is defined as a DAG graph that connects a mixture of abstract and materialized datasets and operators. The missing information needed for describing the DAG graph is a set of edges. For example the description of the previous workflow can be created using the following list of edges (d1 is the output of TF_IDF and d2 is the output of k-Means).</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>crawlDocuments,TF_IDF,0
TF_IDF,d1,0
d1,k-Means,0
k-Means,d2,0
d2,$$target
</pre></div>
</div>
<div class="figure" id="id4">
<img alt="../_images/abstractworkflow.png" src="../_images/abstractworkflow.png" />
<p class="caption"><span class="caption-text">Abstract Workflow Description</span></p>
</div>
<p>For each edge definition the input position should be defined at the end of each line. For example, in this line</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">crawlDocuments</span><span class="p">,</span><span class="n">TF_IDF</span><span class="p">,</span><span class="mi">0</span>
</pre></div>
</div>
<p>The &#8220;0&#8221; defines that the crawlDocuments dataset is the first input to the TF_IDF operator. Also in the following line</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">k</span><span class="o">-</span><span class="n">Means</span><span class="p">,</span><span class="n">d2</span><span class="p">,</span><span class="mi">0</span>
</pre></div>
</div>
<p>the &#8220;0&#8221; again defines that the output of k-Means is the first input of d2. Let&#8217;s assume a workflow consisting of operators with more than one inputs.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">in0</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="mi">0</span>
<span class="n">in1</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="mi">1</span>
<span class="n">test</span><span class="p">,</span><span class="n">o0</span><span class="p">,</span><span class="mi">0</span>
<span class="n">test</span><span class="p">,</span><span class="n">o1</span><span class="p">,</span><span class="mi">1</span>
</pre></div>
</div>
<p>In this example the <em>test</em> operator takes two inputs. The first input to this operator is the <em>in0</em> while the second is the <em>in1</em>.</p>
<p>A  special  tag  $$target  is  used  to  define  which  dataset  is  the  final  output  of  the  DAG graph.</p>
</div>
</div>
<div class="section" id="enforcer-module">
<h2>Enforcer module<a class="headerlink" href="#enforcer-module" title="Permalink to this headline">¶</a></h2>
<p>This  module undertakes the execution of the selected execution plan. The enforcer module is build on top of the YARN  resource  scheduler.  The  enforcer  module  requests  container  resources  from YARN in order to launch the execution of operators. It also orchestrates the execution of a  DAG  graph  of  operators  in  order  to  successfully  execute  the  selected  workflow execution plans.</p>
<div class="section" id="yarn-workflow-execution-engine">
<h3>YARN workflow execution engine<a class="headerlink" href="#yarn-workflow-execution-engine" title="Permalink to this headline">¶</a></h3>
<p>The enforcer module extends the Apache  Kitten framework. Apache  Kitten  is  a  framework  that  lets you  define  the execution  of  operators  on  top  of  YARN.  It  allows  the  description  of  resource configuration  (CPU,  RAM  etc.  of  the  containers  launched)  as  well  as  the  execution configuration of the script or commands that need to be executed inside the allocated container resources. Kitten makes extensive use  of  Lua  tables to  organize  information  about  how  a  YARN  application  should  be executed. Here is how Kitten defines an example of a distributed shell application:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">distshell</span> <span class="o">=</span> <span class="n">yarn</span> <span class="p">{</span>
                <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Distributed Shell&quot;</span><span class="p">,</span>
                <span class="n">timeout</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
                <span class="n">memory</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
                <span class="n">master</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">env</span> <span class="o">=</span> <span class="n">base_env</span><span class="p">,</span> <span class="o">--</span> <span class="n">Defined</span> <span class="n">elsewhere</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">file</span>
                <span class="n">command</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">base</span><span class="o">=</span><span class="s2">&quot;java -Xmx128m com.cloudera.kitten.appmaster.ApplicationMaster&quot;</span><span class="p">,</span>
                        <span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
                                <span class="s2">&quot;-conf job.xml&quot;</span> <span class="p">},</span>
                                <span class="p">}</span>
                        <span class="p">},</span>
                        <span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
                                <span class="n">instances</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                                <span class="n">env</span> <span class="o">=</span> <span class="n">base_env</span><span class="p">,</span>  <span class="o">--</span> <span class="n">Defined</span> <span class="n">elsewhere</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">file</span>
                                <span class="n">command</span> <span class="o">=</span> <span class="s2">&quot;echo &#39;Hello World!&#39; &gt;&gt; /tmp/hello_world&quot;</span>
                        <span class="p">}</span>
                <span class="p">}</span>
</pre></div>
</div>
<p>The <em>yarn</em> function  of  the  Lua  description  provides  all  the  required  information  for running an operator using YARN. The following fields can be defined in the Lua table that is passed to it, optionally setting default values for optional fields that were not specified:</p>
<ol class="arabic simple">
<li><strong>name</strong> (string, required): The name of this application.</li>
<li><strong>timeout</strong> (integer, defaults to -1): How long the client should wait in milliseconds before killing the application due to a timeout. If &lt; 0, then the client will wait forever.</li>
<li><strong>user</strong> (string, defaults to the user executing the client): The user to execute the application as on the Hadoop cluster.</li>
<li><strong>queue</strong> (string,  defaults  to  &#8220;&#8221;):  The  queue  to  submit  the  job  to,  if  the  capacity scheduler is enabled on the cluster.</li>
<li><strong>conf</strong> (table,  optional):  A  table  of  key-value  pairs  that will  be  added  to theConfigurationinstance that is passed to the launched containers via the job.xml file. The creation of job.xml is built-in to the Kitten framework and is similar to how  the  MapReduce  library  uses  the  Configuration  object  to  pass  client-side configuration information to tasks executing on the cluster.</li>
<li><strong>env</strong> (table, optional): A table of key-value pairs that will be set as environment variables in the container. Note that if all of the environment variables are the same for the master and container, you can specify theenvtable once in the yarn table and it will be linked to the subtables by theyarnfunction.</li>
<li><strong>memory</strong> (integer,  defaults  to  512):  The  amount  of  memory  to  allocate  for  the container, in megabytes. If the same amount of memory is allocated for both the master and the containers, you can specify the value once inside of the yarn table and it will be linked to the subtables by theyarnfunction.</li>
<li><strong>cores</strong> (integer,  defaults  to  1):  The  number  of  virtual  cores  to  allocate  for  the container. If the same number of cores is allocated for both the master and the containers, you can specify the value once inside of the yarn table and it will be linked to the subtables by theyarnfunction.</li>
<li><strong>instances</strong> (integer, defaults to 1): The number of instances of this container type to   create   on   the   cluster.   Note   that   this   only   applies   to thecontainer/containersarguments;  the  system  will  only  allocate  a  single master for each application.</li>
<li><strong>priority</strong> (integer, defaults to 0): The relative priority of the containers that are allocated. Note that this prioritization is internal to each application; it does not control how many resources the application is allowed to use or how they are prioritized.</li>
<li><strong>tolerated_failures</strong> (integer,  defaults  to  4):  This  field  is  only  specified  on  the application  master,  and  it  specifies  how  many  container  failures  should  be tolerated before the application shuts down.</li>
<li><strong>command/commands</strong> (string(s)  or  table(s),  optional):commandis  a  shortcut forcommandsin the case that there is only a single command that needs to be executed within each container. This field can either be a string that will be run as-is, or it may be a table that contains two subfields: abasefield that is a string and  anargsfield  that  is  a  table.  Kitten  will  construct  a  command  by concatenating the values in the args table to the base string to form the command to execute.</li>
<li><strong>resources</strong> (table of tables, optional): The resources (in terms of files, URLs, etc.) that  the  command  needs  to  run  in  the  container.  YARN  has  a  mechanism  for copying files that are needed by an application to a working directory created for the container that the application will run in. These files are referred to in Kitten asresources.</li>
</ol>
</div>
<div class="section" id="execution-description">
<h3>Execution description<a class="headerlink" href="#execution-description" title="Permalink to this headline">¶</a></h3>
<p>All  materialized  operators  are  accompanied  by  a  set  of execution  metadata  that  are  used  for  their  actual  execution.  The  main  part  of  the execution description is the lua script that was mentioned in the previous section and is used  to  describe  the  execution  details  of  an  operator.  An  example  description  of  an operator using a lua script is presented below:</p>
<p>&#8211; Resource and environment setup.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">base_resources</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">[</span><span class="s2">&quot;master.jar&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">file</span> <span class="o">=</span> <span class="n">MASTER_JAR_LOCATION</span>
                <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">base_env</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">CLASSPATH</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">concat</span><span class="p">({</span><span class="s2">&quot;$</span><span class="si">{CLASSPATH}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">CP</span><span class="p">,</span> <span class="s2">&quot;./master.jar&quot;</span><span class="p">,</span> <span class="s2">&quot;./tfidf_mahout.sh&quot;</span><span class="p">},</span> <span class="s2">&quot;:&quot;</span><span class="p">),</span>

                <span class="p">}</span>
                <span class="o">--</span> <span class="n">The</span> <span class="n">actual</span> <span class="n">distributed</span> <span class="n">shell</span> <span class="n">job</span><span class="o">.</span>
                <span class="n">operator</span> <span class="o">=</span> <span class="n">yarn</span> <span class="p">{</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;TF/IDF using mahout library&quot;</span><span class="p">,</span>
                        <span class="n">timeout</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">memory</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
                        <span class="n">cores</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                        <span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
                                <span class="n">instances</span> <span class="o">=</span> <span class="n">CONTAINER_INSTANCES</span><span class="p">,</span>
                                <span class="n">env</span> <span class="o">=</span> <span class="n">base_env</span><span class="p">,</span>
                                <span class="n">resources</span> <span class="o">=</span> <span class="p">{</span>
                                        <span class="p">[</span><span class="s2">&quot;tfidf_mahout.sh&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                                                <span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;/opt/asap-server/asapLibrary/operators/TF_IDF_mahout/tfidf_mahout.sh&quot;</span><span class="p">,</span>
                                                <span class="nb">type</span> <span class="o">=</span> <span class="s2">&quot;file&quot;</span><span class="p">,</span>
                 <span class="o">--</span> <span class="n">other</span> <span class="n">value</span><span class="p">:</span> <span class="s1">&#39;archive&#39;</span>
                        <span class="n">visibility</span> <span class="o">=</span> <span class="s2">&quot;application&quot;</span><span class="p">,</span>
                 <span class="o">--</span> <span class="n">other</span> <span class="n">values</span><span class="p">:</span> <span class="s1">&#39;private&#39;</span><span class="p">,</span> <span class="s1">&#39;public&#39;</span>
                        <span class="p">}</span>     <span class="p">},</span>
                 <span class="n">command</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">base</span> <span class="o">=</span> <span class="n">SHELL_COMMAND</span><span class="p">,</span>
                        <span class="p">}</span>
                 <span class="p">}</span>
                <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Workflow and Operator Definition</a><ul>
<li><a class="reference internal" href="#tree-metadata-framework">Tree-metadata framework</a><ul>
<li><a class="reference internal" href="#constraints">Constraints</a></li>
<li><a class="reference internal" href="#execution">Execution</a></li>
<li><a class="reference internal" href="#optimization">Optimization</a></li>
<li><a class="reference internal" href="#dataset-metadata-description">Dataset metadata description</a></li>
<li><a class="reference internal" href="#operator-metadata-description">Operator metadata description</a></li>
<li><a class="reference internal" href="#tree-metadata-matching">Tree-metadata matching</a></li>
<li><a class="reference internal" href="#abstract-operator-description">Abstract operator description</a></li>
<li><a class="reference internal" href="#abstract-workflow-description">Abstract workflow description</a></li>
</ul>
</li>
<li><a class="reference internal" href="#enforcer-module">Enforcer module</a><ul>
<li><a class="reference internal" href="#yarn-workflow-execution-engine">YARN workflow execution engine</a></li>
<li><a class="reference internal" href="#execution-description">Execution description</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index_ires.html">Intelligent Multi-Engine Resource Scheduler</a><ul>
      <li>Previous: <a href="rest.html" title="previous chapter">REST API</a></li>
      <li>Next: <a href="../spark.html" title="next chapter">Extension of the Apache Spark</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/ires_docs/operator-workflow-definition.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Asap consortium.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/ires_docs/operator-workflow-definition.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>