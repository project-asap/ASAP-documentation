<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Installation &amp; Deployment &#8212; Asap 0.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="top" title="Asap 0.0 documentation" href="../index.html" />
    <link rel="up" title="Intelligent Multi-Engine Resource Scheduler" href="index_ires.html" />
    <link rel="next" title="REST API" href="rest.html" />
    <link rel="prev" title="Introduction" href="intro.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="installation-deployment">
<h1>Installation &amp; Deployment<a class="headerlink" href="#installation-deployment" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installing-ires-platform">
<h2>Installing IReS-Platform<a class="headerlink" href="#installing-ires-platform" title="Permalink to this headline">¶</a></h2>
<p>This section serves as an installation and execution manual for IReS</p>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>To have the IRes platform up and running, 4 steps are required:</p>
<ol class="arabic simple">
<li>Clone IReS code to the server</li>
<li>Run install.sh</li>
<li>Validate installation</li>
<li>Start the IReS server</li>
</ol>
</div>
<div class="section" id="clone-ires-code-to-the-server">
<h3>Clone IReS code to the server<a class="headerlink" href="#clone-ires-code-to-the-server" title="Permalink to this headline">¶</a></h3>
<p>For a quick reference of how to use git, click <a class="reference external" href="https://rogerdudler.github.io/git-guide/">here</a>.
Open a terminal (Linux) and navigate to a desired directory where IReS-Platform files will be cloned e.g. asap. Then, clone the project by entering the following command</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">git</span><span class="nd">@github</span><span class="o">.</span><span class="n">com</span><span class="p">:</span><span class="n">project</span><span class="o">-</span><span class="n">asap</span><span class="o">/</span><span class="n">IReS</span><span class="o">-</span><span class="n">Platform</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
</div>
<div class="section" id="run-install-sh">
<h3>Run install.sh<a class="headerlink" href="#run-install-sh" title="Permalink to this headline">¶</a></h3>
<p>After successful cloning of the IReS platform, various folders and files can be found inside $IRES HOME. Among them there exists install.sh. Assuming that the current working directory is $IRES HOME, executing</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">install</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>will start building IReS. Upon successful build you will be prompted to provide the path where Hadoop YARN is located in your computer. By doing this, IReS gets con-
nected to Hadoop YARN. Alternatively, executing</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>./install.sh -c $YARN_HOME,$IRES_HOME
</pre></div>
</div>
<p>will make the connection of IReS and YARN, where $YARN_HOME and $IRES_HOME correspond to the absolute paths of YARN&#8217;s and IReS&#8217;s home folder.</p>
<p>Assuming that the connections have been established, update the file</p>
<p>$YARN_HOME/etc/hadoop/yarn-site.xml</p>
<p>with the following property values,</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">yarn</span><span class="o">.</span><span class="n">nodemanager</span><span class="o">.</span><span class="n">services</span><span class="o">-</span><span class="n">running</span><span class="o">.</span><span class="n">per</span><span class="o">-</span><span class="n">node</span>
<span class="n">yarn</span><span class="o">.</span><span class="n">nodemanager</span><span class="o">.</span><span class="n">services</span><span class="o">-</span><span class="n">running</span><span class="o">.</span><span class="n">check</span><span class="o">-</span><span class="n">availability</span>
<span class="n">yarn</span><span class="o">.</span><span class="n">nodemanager</span><span class="o">.</span><span class="n">services</span><span class="o">-</span><span class="n">running</span><span class="o">.</span><span class="n">check</span><span class="o">-</span><span class="n">status</span>
</pre></div>
</div>
<p>These properties enable IReS to run workflows over YARN and monitor cluster
resources and services.</p>
</div>
<div class="section" id="validate-installation">
<h3>Validate installation<a class="headerlink" href="#validate-installation" title="Permalink to this headline">¶</a></h3>
<p>If anything goes wrong during the build process of IReS, error messages will be printedout and a log file will be provided.</p>
</div>
<div class="section" id="start-the-ires-server">
<h3>Start the IReS server<a class="headerlink" href="#start-the-ires-server" title="Permalink to this headline">¶</a></h3>
<p>Run IReS server by running the command</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">install</span><span class="o">.</span><span class="n">sh</span> <span class="o">-</span><span class="n">r</span> <span class="n">start</span>
</pre></div>
</div>
<p>No exception should be raised. Also, the jps command should print a &#8220;Main&#8221; process running that corresponds to ASAP server.
Run ASAP server web user interface at <a class="reference external" href="http://your_hostname:1323/web/main">http://your_hostname:1323/web/main</a>. IReS home page should be displayed.
Run a workflow, for example run &#8220;hello_world&#8221; from &#8220;Abstrack Workflows&#8221; tab and see what happens not only in IReS web interface but also in YARN and HDFS web interfaces. Make sure that YARN has been started before running any workflow. Click on &#8220;Cockpit&#8221; tab to verify that the services are running.</p>
</div>
<div class="section" id="monitor">
<h3>Monitor<a class="headerlink" href="#monitor" title="Permalink to this headline">¶</a></h3>
<p>The Monitor is responsible for the profiling of the operators in every workflow execution. It keeps the execution metrics (eg execution time, number of cores etc) in a dictionary format and stores them into a MongoDB server. To install the Monitor:</p>
<ol class="arabic simple">
<li>Install MongoDB. You can follow <a class="reference external" href="https://docs.mongodb.com/manual/administration/install-on-linux/">this tutorial</a>.</li>
<li>Copy the &#8216;asap-tools&#8217; <a class="reference external" href="https://github.com/project-asap/IReS-Platform/tree/master/asap-tools">subproject</a> to every IReS node and also install the required dependencies.</li>
<li>Set the full path of the <cite>asap (asap-tools/bin/asap)</cite> script in the <cite>asap.path parameters of the `asap.properties(asap-server/target/conf/asap.properties)</cite> file.</li>
<li>In each node create a file <cite>/etc/reporter_config.json</cite> with the following content:</li>
</ol>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="p">{</span>
   <span class="s2">&quot;backend&quot;</span><span class="p">:</span> <span class="s2">&quot;mongo&quot;</span><span class="p">,</span>
   <span class="s2">&quot;host&quot;</span><span class="p">:</span><span class="s2">&quot;the_mongo_db_host&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="running-a-sample-workflow">
<h2>Running a sample workflow<a class="headerlink" href="#running-a-sample-workflow" title="Permalink to this headline">¶</a></h2>
<p>The HelloWorld is a simple workflow constists of just a single operator, designed for demonstration purposes. To run the HelloWolrd follow the next steps:</p>
<ol class="arabic simple">
<li>Go to IReS UI: <a class="reference external" href="http://ires_host:1323/web/main">http://ires_host:1323/web/main</a></li>
</ol>
<div class="figure" id="id4">
<img alt="../_images/ireshome.png" src="../_images/ireshome.png" />
<p class="caption"><span class="caption-text">IReS Home Page</span></p>
</div>
<ol class="arabic simple" start="2">
<li>Go to the <strong>Abstract Workflows</strong> tab and select the <strong>HelloWorld</strong> workflow</li>
</ol>
<div class="figure" id="id5">
<img alt="../_images/abstractworkflows.png" src="../_images/abstractworkflows.png" />
<p class="caption"><span class="caption-text">Abstract Workflows Tab</span></p>
</div>
<ol class="arabic simple" start="3">
<li>Then click on <strong>Materialize Workflow</strong> button</li>
</ol>
<div class="figure" id="id6">
<img alt="../_images/abstracthello.png" src="../_images/abstracthello.png" />
<p class="caption"><span class="caption-text">Abstract HelloWorld Workflow</span></p>
</div>
<ol class="arabic simple" start="4">
<li>Click on the <strong>Execute Workflow</strong> button to start the execution</li>
</ol>
<div class="figure" id="id7">
<img alt="../_images/materializedhello.png" src="../_images/materializedhello.png" />
<p class="caption"><span class="caption-text">The materialized HelloWorld workflow</span></p>
</div>
<p>In the figures below we can see the execution process</p>
<div class="figure" id="id8">
<a class="reference internal image-reference" href="../_images/exec1.png"><img alt="../_images/exec1.png" src="../_images/exec1.png" style="width: 150%;" /></a>
<p class="caption"><span class="caption-text">The execution has been started</span></p>
</div>
<div class="figure" id="id9">
<a class="reference internal image-reference" href="../_images/yarn.png"><img alt="../_images/yarn.png" src="../_images/yarn.png" style="width: 150%;" /></a>
<p class="caption"><span class="caption-text">The submitted YARN application</span></p>
</div>
<div class="figure" id="id10">
<a class="reference internal image-reference" href="../_images/exec2.png"><img alt="../_images/exec2.png" src="../_images/exec2.png" style="width: 150%;" /></a>
<p class="caption"><span class="caption-text">The execution has been finished</span></p>
</div>
</div>
<div class="section" id="create-a-workflow-from-scratch">
<h2>Create a workflow from scratch<a class="headerlink" href="#create-a-workflow-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>In this section the process of designing a new workflow from scratch is described. We will create a workflow that consists of a single operator and takes as input a text file and produces as output the number of lines.</p>
<div class="section" id="dataset-definition">
<h3>Dataset definition<a class="headerlink" href="#dataset-definition" title="Permalink to this headline">¶</a></h3>
<p>In order to create the workflow input dataset you need to add the dataset definition into IReS library. Create a file named &#8216;asapServerLog&#8217; into the asapLibrary/datasets/ folder and add the following content:</p>
<div class="code highlight-default"><div class="highlight"><pre><span></span><span class="n">Optimization</span><span class="o">.</span><span class="n">documents</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">path</span><span class="o">=</span><span class="n">hdfs</span>\<span class="p">:</span><span class="o">///</span><span class="n">user</span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">asap</span><span class="o">-</span><span class="n">server</span><span class="o">.</span><span class="n">log</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">FS</span><span class="o">=</span><span class="n">HDFS</span>
</pre></div>
</div>
<p>This step assumes that a file named &#8216;asap-server.log&#8217; exists in the HDFS. You can download the log file used in this example <a class="reference external" href="./files/asap-server.log">through this link</a>.</p>
<ol class="lowerroman simple">
<li>From the bash shell, go to the asapLibrary/operators folder in the IReS installation directory.</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>cd $ASAP HOME/target/asapLibrary/operators
</pre></div>
</div>
<ol class="lowerroman simple" start="2">
<li>Then, create a new folder named with the new materialized operators name.</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">mkdir</span> <span class="n">LineCount</span>
</pre></div>
</div>
<ol class="lowerroman simple" start="3">
<li>Create the description file and enter the information below. A description file should meet the standards of the template provided in this <a class="reference external" href="./files/description_template">this link</a>.. This template contains all the required parameters for an operator to run as long as all the optional parameters which can be used.</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>Constraints.Engine=Spark
Constraints.Output.number=1
Constraints.Input.number=1
Constraints.OpSpecification.Algorithm.name=LineCount
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.outputSpace.execTime=Double
Optimization.outputSpace.cost=Double
Optimization.cost=1.0
Optimization.execTime=1.0
Execution.Arguments.number=2
Execution.Argument0=In0.path.local
Execution.Argument1=lines.out
Execution.Output0.path=$HDFS_OP_DIR/lines.out
Execution.copyFromLocal=lines.out
Execution.copyToLocal=In0.path
</pre></div>
</div>
<ol class="lowerroman simple" start="4">
<li>Create the .lua file with the execution instructions</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>operator = yarn {
        name = &quot;LineCount&quot;,
        timeout = 10000,
        memory = 1024,
        cores = 1,
        container = {
                instances = 1,
                --env = base_env,
                resources = {
                        [&quot;count_lines.sh&quot;] = {
                                file = &quot;asapLibrary/operators/LineCount/count_lines.sh&quot;,
                                type = &quot;file&quot;,
                                -- other value: ’archive’
                                visibility = &quot;application&quot; -- other values: ’private’, ’public’
                        }
                },
                command = {
                        base = &quot;./.sh&quot;
                }
        }
}
</pre></div>
</div>
<ol class="loweralpha" start="22">
<li><p class="first">Create the executable named count lines.sh with the following content</p>
<blockquote>
<div></div></blockquote>
</li>
</ol>
<ol class="lowerroman" start="6">
<li><p class="first">Restart the IReS server</p>
<blockquote>
<div><p>..code:: javascript</p>
<blockquote>
<div><p>$ IRES_HOME/asap-server/src/main/scripts/asap-server restart</p>
</div></blockquote>
</div></blockquote>
</li>
</ol>
</div>
<div class="section" id="materialized-operator-definition-via-rest">
<h3>Materialized Operator Definition (via REST)<a class="headerlink" href="#materialized-operator-definition-via-rest" title="Permalink to this headline">¶</a></h3>
<p>In this example we describe an alternative way to create a materialized operator with the REST API. To do so, create a folder locally and add the required description file as well as all other files needed for the execution. In this case, an extra parameter should be added to the description file which defines the execution command (Execution.command).</p>
<ol class="lowerroman simple">
<li>description file: Create inside the folder a file named <cite>description</cite> with the following content:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>Constraints.Engine=Spark
Constraints.Output.number=1
Constraints.Input.number=1
Constraints.OpSpecification.Algorithm.name=LineCount
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.outputSpace.execTime=Double
Optimization.outputSpace.cost=Double
Optimization.cost=1.0
Optimization.execTime=1.0
Execution.Arguments.number=2
Execution.Argument0=In0.path.local
Execution.Argument1=lines.out
Execution.Output0.path=$HDFS_OP_DIR/lines.out
Execution.copyFromLocal=lines.out
Execution.copyToLocal=In0.path
Execution.command=./count_lines.sh
</pre></div>
</div>
<ol class="lowerroman simple" start="2">
<li>executable file: Create the executable named &#8216;count_lines.sh&#8217; with the following content:</li>
</ol>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>#!/bin/bash
wc -l $1 &gt;&gt; $2
</pre></div>
</div>
<p>and make it executable</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">chmod</span> <span class="o">+</span><span class="n">x</span> <span class="n">count_lines</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<ol class="lowerroman simple" start="3">
<li>Send the operator via the &#8216;send_operator.sh&#8217; script:</li>
</ol>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">send_operator</span><span class="o">.</span><span class="n">sh</span> <span class="n">LOCAL_OP_FOLDER</span> <span class="n">IRES_HOST</span> <span class="n">LineCount</span>
</pre></div>
</div>
<p>The script is available at $IRES_HOME/asap-server/src/main/scripts. You can also <a class="reference external" href="https://github.com/project-asap/IReS-Platform/blob/master/asap-platform/asap-server/src/main/scripts/send_operator.sh">download it directly</a>.</p>
</div>
<div class="section" id="abstract-operator-definition">
<h3>Abstract operator definition<a class="headerlink" href="#abstract-operator-definition" title="Permalink to this headline">¶</a></h3>
<p>Create the <cite>LineCount</cite> abstract operator by creating a file named &#8216;LineCount&#8217; in the asapLibrary/abstractOperators folder with the following content:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="o">.</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="o">.</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">OpSpecification</span><span class="o">.</span><span class="n">Algorithm</span><span class="o">.</span><span class="n">name</span><span class="o">=</span><span class="n">LineCount</span>
</pre></div>
</div>
</div>
<div class="section" id="abstract-workflow-definition-server-side">
<h3>Abstract workflow definition (Server-Side)<a class="headerlink" href="#abstract-workflow-definition-server-side" title="Permalink to this headline">¶</a></h3>
<p>Create the <cite>LineCountWorkflow</cite> workflow by creating a folder named &#8216;LineCountWorkflow&#8217; in the asapLibrary/abstractWorkflows. The abstract workflow folder should consist of three required components: the <cite>datasets</cite> folder , the <cite>operators</cite> folder and a file named <cite>graph</cite>.</p>
<ol class="lowerroman simple">
<li>Create a folder named &#8216;datasets&#8217; and copy the <cite>asapServerLog</cite> file from the <cite>asapLibrary/datasets/</cite> folder into it. Then, create an empty file named &#8216;d1&#8217; (touch d1).</li>
<li>Create a file named &#8216;graph&#8217; and add the following content:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>asapServerLog,LineCount,0
LineCount,d1,0
d1,$$target
</pre></div>
</div>
<p>This <cite>graph</cite> file defines the workflow graph as follows: <cite>asapServerLog</cite> dataset is being given as input to the <cite>LineCount</cite> abstract operator and <cite>LineCount</cite> operator outputs the result into <cite>d1</cite>. Finally, <cite>d1</cite> node maps to the final result ($$target).</p>
<ol class="lowerroman simple" start="3">
<li>operators: Create a folder named &#8216;operators&#8217; which will contain the operators involved in the worflow. In the &#8216;operators&#8217; folder create a file named &#8216;LineCount&#8217; and add the following content:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Engine</span><span class="o">=</span><span class="n">Spark</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="o">.</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="o">.</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">OpSpecification</span><span class="o">.</span><span class="n">Algorithm</span><span class="o">.</span><span class="n">name</span><span class="o">=</span><span class="n">LineCount</span>
</pre></div>
</div>
<ol class="lowerroman simple" start="4">
<li>Restart the server for changes to take effect.</li>
</ol>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>$IRES_HOME/asap-platform/asap-server/src/main/scripts/asap-server restart
</pre></div>
</div>
</div>
<div class="section" id="abstract-workflow-definition-gui">
<h3>Abstract Workflow Definition (GUI):<a class="headerlink" href="#abstract-workflow-definition-gui" title="Permalink to this headline">¶</a></h3>
<p>Alternatively, the abstract workflow can be defined through the Web UI as follows.
i. Go to the <cite>Abstract Workflows</cite> tab. Enter the name ”LineCountWorkflow” in the Name textbox and click the <cite>New Workflow</cite> button.
ii. Then we add the workflow parts one-by-one. First we add the asapServer-Log dataset from the dataset library. Select the <cite>Materialized Dataset</cite> radio
button and enter the dataset name in the Comma seperated list text box. Then click the <cite>Add nodes</cite> button to add the dataset node to the workflow graph. Repeat this step to add an output node with name d1. Just enter the name <cite>d1</cite> to the text box and click the <cite>Add nodes</cite> button.
iii. Add the LineCount abstract operator to the workflow. Select the <cite>Abstract Operator</cite> radio button, enter the operators name (LineCount) in the text box and click again the <cite>Add nodes</cite> button.
iv. Describe the workflow by connecting the graph nodes defined in the previous steps, by entering the following text in the large text box:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>asapServerLog,LineCount
LineCount,d1
d1,$$target
</pre></div>
</div>
<p>Click the <cite>Change graph</cite> button</p>
</div>
<div class="section" id="workflow-materialization">
<h3>Workflow Materialization<a class="headerlink" href="#workflow-materialization" title="Permalink to this headline">¶</a></h3>
<p>To materialize the workflow navigate to the <cite>Abstract Workflows</cite> tab and click on the LineCountWorkflow created in the previous steps.</p>
<a class="reference internal image-reference" href="../_images/abstractLineCount.png"><img alt="../_images/abstractLineCount.png" src="../_images/abstractLineCount.png" style="width: 150%;" /></a>
<p>Click on the <cite>Materialize Workflow</cite> button</p>
<a class="reference internal image-reference" href="../_images/lineCountMaterialized.png"><img alt="../_images/lineCountMaterialized.png" src="../_images/lineCountMaterialized.png" style="width: 150%;" /></a>
<p>Now you can see the materialized LineCount workflow. Click on <cite>Execute Workflow</cite> button to trigger the execution</p>
<a class="reference internal image-reference" href="../_images/lineCountExecution.png"><img alt="../_images/lineCountExecution.png" src="../_images/lineCountExecution.png" style="width: 150%;" /></a>
<p>When the execution finish, navigate to the HDFS file browser to see the output located at appN folder.</p>
<a class="reference internal image-reference" href="../_images/lineCountHDFS.png"><img alt="../_images/lineCountHDFS.png" src="../_images/lineCountHDFS.png" style="width: 150%;" /></a>
<p>All resources and examples files described in this section are available <a class="reference external" href="./files/LineCountExample.tar">here</a>.</p>
</div>
</div>
<div class="section" id="creating-a-text-clustering-workflow">
<h2>Creating a text clustering workflow<a class="headerlink" href="#creating-a-text-clustering-workflow" title="Permalink to this headline">¶</a></h2>
<p>This example describes how to define a text clustering workflow consisting of two operators. This workflow takes as input a dataset with raw text files. In the first operator
the files are transformed into tf-idf vectors. Then the vectors are given as input to the next operator which performs the clustering using a k-means algorithm. We will use
two Cilk-based implementations for this example, and we will create all the required files and directories using the server-side method.</p>
<div class="section" id="id2">
<h3>Dataset definition<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>We will use this text file for our example. The following file should exists in the HDFS cluster with name &#8216;textData&#8217;. Create the data definition as follows:
1. Create a file named &#8216;textData&#8217; in the asapLibrary/datasets folder
2. Add the following content:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Engine</span><span class="o">.</span><span class="n">FS</span> <span class="o">=</span> <span class="n">HDFS</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">text</span>
<span class="n">Execution</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">///</span><span class="n">user</span><span class="o">/</span><span class="n">asap</span><span class="o">/</span><span class="nb">input</span><span class="o">/</span><span class="n">textData</span>
<span class="n">Optimization</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="mi">932</span><span class="n">E06</span>
</pre></div>
</div>
</div>
<div class="section" id="tf-idf-abstract-operator-definition">
<h3>TF-IDF abstract operator definition<a class="headerlink" href="#tf-idf-abstract-operator-definition" title="Permalink to this headline">¶</a></h3>
<p>Next, we&#8217;ll define the abstract definition for a TF-IDF operator.
1. Create a file named &#8216;tf-idf&#8217; in the asapLibrary/abstractOperators folder
2. Add the following content:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">OpSpecification</span><span class="o">.</span><span class="n">Algorithm</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">TF_IDF</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="k-means-abstract-operator-definition">
<h3>K-Means abstract operator definition<a class="headerlink" href="#k-means-abstract-operator-definition" title="Permalink to this headline">¶</a></h3>
<p>Create the abstract definition of K-Means operator as follows:
1. Create a file named &#8216;kmeans&#8217; in the asapLibrary/abstractOperators folder
2. Add the following content:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">Constraints</span><span class="o">.</span><span class="n">Input</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">OpSpecification</span><span class="o">.</span><span class="n">Algorithm</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">kmeans</span>
<span class="n">Constraints</span><span class="o">.</span><span class="n">Output</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="abstract-workflow-definition">
<h3>Abstract workflow definition<a class="headerlink" href="#abstract-workflow-definition" title="Permalink to this headline">¶</a></h3>
<p>In this step we&#8217;ll describe how to connect the two aforementioned operators in order to define the text clustering workflow.
1. Create a folder named &#8216;TextClustering&#8217; in the asabLibrary/abstractWorkflows folder
2. Specify the workflow graph by creating a file named &#8216;graph&#8217; with the following content:</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>testdir,tfidf_cilk,0
tfidf_cilk,d1,0
d1,kmeans,0
kmeans,d2,0
d2,$$target
</pre></div>
</div>
<p>Next, we will defined the materialized operators. We will use Cilk for our implementations.</p>
</div>
<div class="section" id="tf-idf-materialized-operator-definition-cilk">
<h3>TF-IDF materialized operator definition (Cilk)<a class="headerlink" href="#tf-idf-materialized-operator-definition-cilk" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Create a folder named &#8216;TF_IDF_cilk&#8217; in the asapLibrary/operators folder.</li>
<li>Create the description file named &#8216;description&#8217; and add the following content:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>Constraints.Output0.Engine.FS=HDFS
Constraints.OpSpecification.Algorithm.name=TF_IDF
Constraints.Input0.type=text
Constraints.Output0.type=arff
Constraints.Engine=Cilk
Constraints.Output.number=1
Constraints.Input.number=1
Execution.LuaScript=TF_IDF_cilk.lua
Execution.Arguments.number=2
Execution.Argument0=In0.path.local
Execution.Argument1=tfidf.out
Execution.copyFromLocal=tfidf.out
Execution.copyToLocal=In0.path
Execution.Output0.path=$HDFS_OP_DIR/tfidf.out
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li>Create the lua file named &#8216;TF_IDF_cilk.lua&#8217; as follows:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">operator</span> <span class="o">=</span> <span class="n">yarn</span> <span class="p">{</span>
  <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Execute cilk tfidf&quot;</span><span class="p">,</span>
  <span class="n">timeout</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
  <span class="n">memory</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
  <span class="n">cores</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
  <span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="o">--</span><span class="n">env</span> <span class="o">=</span> <span class="n">base_env</span><span class="p">,</span>
    <span class="n">resources</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">[</span><span class="s2">&quot;tfidf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
       <span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;asapLibrary/operators/TF_IDF_cilk/tfidf&quot;</span><span class="p">,</span>
                <span class="nb">type</span> <span class="o">=</span> <span class="s2">&quot;file&quot;</span><span class="p">,</span>               <span class="o">--</span> <span class="n">other</span> <span class="n">value</span><span class="p">:</span> <span class="s1">&#39;archive&#39;</span>
                <span class="n">visibility</span> <span class="o">=</span> <span class="s2">&quot;application&quot;</span>  <span class="o">--</span> <span class="n">other</span> <span class="n">values</span><span class="p">:</span> <span class="s1">&#39;private&#39;</span><span class="p">,</span> <span class="s1">&#39;public&#39;</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="n">command</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;export LD_LIBRARY_PATH=/0/asap/qub/gcc-5/lib64:$LD_LIBRARY_PATH ; ./tfidf&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>Add the &#8216;tfidf&#8217; executable (can be found in the tarball provided in the end of this article).</li>
</ol>
</div>
<div class="section" id="k-means-materialized-operator-definition-cilk">
<h3>K-Means materialized operator definition (Cilk)<a class="headerlink" href="#k-means-materialized-operator-definition-cilk" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Create a folder named &#8216;kmeans_cilk&#8217; in the asapLibrary/operators folder.</li>
<li>Create the description file named &#8216;description&#8217; and add the following content:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>Constraints.Output0.Engine.FS=HDFS
Constraints.OpSpecification.Algorithm.name=kmeans
Constraints.Input0.Engine.FS=HDFS
Constraints.Input0.type=arff
Constraints.Engine=Spark
Constraints.Output.number=1
Constraints.Input.number=1
Execution.LuaScript=kmeans_cilk.lua
Execution.Arguments.number=2
Execution.Argument0=In0.path.local
Execution.Argument1=kmeans.out
Execution.copyFromLocal=kmeans.out
Execution.copyToLocal=In0.path
Execution.Output0.path=$HDFS_OP_DIR/kmeans.out
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li>Create the lua file named &#8216;kmeans_cilk.lua&#8217; as follows:</li>
</ol>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">operator</span> <span class="o">=</span> <span class="n">yarn</span> <span class="p">{</span>
  <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Execute kmeans&quot;</span><span class="p">,</span>
  <span class="n">timeout</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
  <span class="n">memory</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
  <span class="n">cores</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
  <span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="o">--</span><span class="n">env</span> <span class="o">=</span> <span class="n">base_env</span><span class="p">,</span>
    <span class="n">resources</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">[</span><span class="s2">&quot;kmeans&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
       <span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;asapLibrary/operators/kmeans_cilk/kmeans&quot;</span><span class="p">,</span>
                <span class="nb">type</span> <span class="o">=</span> <span class="s2">&quot;file&quot;</span><span class="p">,</span>               <span class="o">--</span> <span class="n">other</span> <span class="n">value</span><span class="p">:</span> <span class="s1">&#39;archive&#39;</span>
                <span class="n">visibility</span> <span class="o">=</span> <span class="s2">&quot;application&quot;</span>  <span class="o">--</span> <span class="n">other</span> <span class="n">values</span><span class="p">:</span> <span class="s1">&#39;private&#39;</span><span class="p">,</span> <span class="s1">&#39;public&#39;</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="n">command</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;export LD_LIBRARY_PATH=/0/asap/qub/gcc-5/lib64:$LD_LIBRARY_PATH ; ./kmeans&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>Add the &#8216;kmeans&#8217; executable (can be also found in the tarball).</li>
</ol>
</div>
<div class="section" id="execute-the-workflow">
<h3>Execute the workflow<a class="headerlink" href="#execute-the-workflow" title="Permalink to this headline">¶</a></h3>
<p>After finishing the previous steps restart the server for changes to take effect. Then:
1. Go to Abstract Workflows and click on TextClustering</p>
<a class="reference internal image-reference" href="../_images/abstract.png"><img alt="../_images/abstract.png" src="../_images/abstract.png" style="width: 150%;" /></a>
<ol class="arabic simple" start="2">
<li>Materialize the workflow by clicking &#8216;Materialize&#8217; button</li>
</ol>
<a class="reference internal image-reference" href="../_images/materialized.png"><img alt="../_images/materialized.png" src="../_images/materialized.png" style="width: 150%;" /></a>
<ol class="arabic simple" start="3">
<li>Start the workflow execution by clicking &#8216;Execute&#8217; button</li>
</ol>
<a class="reference internal image-reference" href="../_images/running.png"><img alt="../_images/running.png" src="../_images/running.png" style="width: 150%;" /></a>
<p>The files used in this example can be downloaded <a class="reference external" href="./files/TextClustering.tar">here</a>.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Installation &amp; Deployment</a><ul>
<li><a class="reference internal" href="#installing-ires-platform">Installing IReS-Platform</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#clone-ires-code-to-the-server">Clone IReS code to the server</a></li>
<li><a class="reference internal" href="#run-install-sh">Run install.sh</a></li>
<li><a class="reference internal" href="#validate-installation">Validate installation</a></li>
<li><a class="reference internal" href="#start-the-ires-server">Start the IReS server</a></li>
<li><a class="reference internal" href="#monitor">Monitor</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-a-sample-workflow">Running a sample workflow</a></li>
<li><a class="reference internal" href="#create-a-workflow-from-scratch">Create a workflow from scratch</a><ul>
<li><a class="reference internal" href="#dataset-definition">Dataset definition</a></li>
<li><a class="reference internal" href="#materialized-operator-definition-via-rest">Materialized Operator Definition (via REST)</a></li>
<li><a class="reference internal" href="#abstract-operator-definition">Abstract operator definition</a></li>
<li><a class="reference internal" href="#abstract-workflow-definition-server-side">Abstract workflow definition (Server-Side)</a></li>
<li><a class="reference internal" href="#abstract-workflow-definition-gui">Abstract Workflow Definition (GUI):</a></li>
<li><a class="reference internal" href="#workflow-materialization">Workflow Materialization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#creating-a-text-clustering-workflow">Creating a text clustering workflow</a><ul>
<li><a class="reference internal" href="#id2">Dataset definition</a></li>
<li><a class="reference internal" href="#tf-idf-abstract-operator-definition">TF-IDF abstract operator definition</a></li>
<li><a class="reference internal" href="#k-means-abstract-operator-definition">K-Means abstract operator definition</a></li>
<li><a class="reference internal" href="#abstract-workflow-definition">Abstract workflow definition</a></li>
<li><a class="reference internal" href="#tf-idf-materialized-operator-definition-cilk">TF-IDF materialized operator definition (Cilk)</a></li>
<li><a class="reference internal" href="#k-means-materialized-operator-definition-cilk">K-Means materialized operator definition (Cilk)</a></li>
<li><a class="reference internal" href="#execute-the-workflow">Execute the workflow</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index_ires.html">Intelligent Multi-Engine Resource Scheduler</a><ul>
      <li>Previous: <a href="intro.html" title="previous chapter">Introduction</a></li>
      <li>Next: <a href="rest.html" title="next chapter">REST API</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/ires_docs/install.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Asap consortium.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.9</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../_sources/ires_docs/install.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>