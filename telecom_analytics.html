<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Telecommunication Analytics &#8212; Asap 0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="top" title="Asap 0.0 documentation" href="index.html" />
    <link rel="prev" title="Analytics Programming Model - SWAN Compiler" href="swan.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="telecommunication-analytics">
<h1>Telecommunication Analytics<a class="headerlink" href="#telecommunication-analytics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The goal of WIND was to design and implement a new application to take better advantage of the new big data approach for mobile applications. The ASAP telecommunications  application  will  show  how  a  number  of  analytical  services describing the mobility of people can be created on the basis of the data collected by the mobile network during routine operation. We developed three modules: the user profiling, the sociometer and the peak detection.   Moreover  some  additional  modules  are  defined and  developed  in  order  to  build  complete  workflows  going  from  the  data  to  the publication of the results, as shown in the figure below.</p>
<img alt="_images/WIND_general_modules.png" src="_images/WIND_general_modules.png" />
</div>
<div class="section" id="peak-detection">
<h2>Peak Detection<a class="headerlink" href="#peak-detection" title="Permalink to this headline">¶</a></h2>
<p>This analysis detects relevant peaks representing an event. This is achieved by comparing the density of population (measured in calls) within a region in a given moment against the expected density for that area at that hour of the day.</p>
<p>The overall analysis is decomposed in the following operators:</p>
<blockquote>
<div>Data Filter
Distribution Computation
Peak Detection</div></blockquote>
<p>The above operators are implemented as Spark applications (using the scala API) and they can be executed by submitting them to a running Spark installation.</p>
<p>The overall calculation is illustrated here:</p>
<img alt="_images/PeakDetection.png" src="_images/PeakDetection.png" />
<div class="section" id="data-filter">
<h3>Data Filter<a class="headerlink" href="#data-filter" title="Permalink to this headline">¶</a></h3>
<p>This is the first step of the Peak Detection calculation.</p>
<p>The process expects a CDR dataset containing the following fields:</p>
<blockquote>
<div><ol class="arabic simple">
<li>caller id (masked)</li>
<li>call date (format: yyyy-MM-dd)</li>
<li>chargable duration</li>
<li>tower identifier from which the call has initiated</li>
<li>tower identifier where the call has ended</li>
</ol>
</div></blockquote>
<p>Then, the process assumes a dataRaw dataset derived from the above and containing the following fields:</p>
<blockquote>
<div><ul class="simple">
<li>id : tower identifier from which the call has initiated</li>
<li>hour: the hour of the day (derived by the call date)</li>
<li>dow: the day of the week (derived by the call date)</li>
<li>doy: the day of the year (derived by the call date)</li>
<li>num: the number of calls started in this tower range at this hour of this specific day.</li>
</ul>
</div></blockquote>
<p>The next step of the process consists in defining the geographical area to analyze and to partition it into a set of regions. The same must be done for the time, where a timeframe is chosen (for instance, a month), partitioned into periods (for instance, days) and then into smaller time slots (for instance, hours). Time slots are described by a parameter T, while the regions that cover the area of analysis are described by a parameter S, both parameters being provided by the user. These two parameters, then, allow defining a spatio-temporal grid, and each observation of an input dataset can be assigned to one of its cells. The number of observations that fall in a cell defines its density. The input data is partitioned into two sets: a training dataset and a test dataset. For both datasets the spatiotemporal grid of densities is computed. The first will be used to compute the densities of a typical period for each region. The second dataset will be then compared against such typical period in order to detect significant deviations.</p>
<div class="section" id="implementation-details">
<h4>Implementation Details<a class="headerlink" href="#implementation-details" title="Permalink to this headline">¶</a></h4>
<p>As an spark application, this operator can be executed by being submitted in an running spark installation. For simplifying the execution submit.sh can be used.</p>
<p>Usage: ./submit.sh ta.DataFilter &lt;master&gt; &lt;cdrPath&gt; &lt;output&gt; &lt;trainingSince (yyyy-MM-dd)&gt; &lt;trainingUntil (yyyy-MM-dd)&gt; &lt;testSince (yyyy-MM-dd)&gt; &lt;testUntil (yyyy-MM-dd or None)&gt; &lt;voronoiPath&gt;</p>
<p><strong>Input parameters</strong>:</p>
<blockquote>
<div><ol class="arabic simple">
<li>The spark master URI</li>
<li>The input CDR dataset (HDFS or local)</li>
<li>The ouput path (an non existing HDFS or local directory)</li>
<li>The start date for the training period (format yyyy-MM-dd)</li>
<li>The end date for the training period (format yyyy-MM-dd)</li>
<li>The start date for the test period (format yyyy-MM-dd)</li>
<li>The end date for the training period (format yyyy-MM-dd) or None</li>
<li>The path to the voronoi table: the set of towers ids in analysis.</li>
</ol>
</div></blockquote>
<p><strong>Output</strong>: Upon successful execution the &lt;output&gt;/trainingData &amp; &lt;output&gt;/testData datasets will be created.</p>
<p>e.g.: ./submit.sh ta.DataFilter spark://localhost:7077 /dataset_simulated /output 2015-06-01 2015-06-02 2015-06-03 None /voronoi</p>
</div>
</div>
<div class="section" id="distribution-computation">
<h3>Distribution Computation<a class="headerlink" href="#distribution-computation" title="Permalink to this headline">¶</a></h3>
<p>This is the second step of the Peak Detection calculation and it requires input generated by the Data Filter step.</p>
<p>Based on the densities obtained for each region and each time slot over the training dataset, an expected density value is computed for each region, by averaging the densities measured at the same time slot of all the periods in the time window covered by the dataset. For instance, we might obtain an expected density for each pair (region, hour of the day), i.e., 24 values for each region, assuming 24 one-hour time-slots. The result represents the standard behavior and it is saved in a new dataset named cpBase.</p>
<div class="section" id="id1">
<h4>Implementation Details<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>As an spark application, this operator can be executed by being submitted in an running spark installation. For simplifying the execution submit.sh can be used.</p>
<p>Usage: ./submit.sh ta.DistributionComputation &lt;master&gt; &lt;trainingDataFile&gt; &lt;output&gt;</p>
<p><strong>Input parameters</strong>:</p>
<blockquote>
<div><ol class="arabic simple">
<li>The spark master URI</li>
<li>The training dataset URI (HDFS or local) (created during the data filtering step)</li>
<li>The ouput path (an non existing HDFS or local directory)</li>
</ol>
</div></blockquote>
<p><strong>Output</strong>: Upon successful execution the &lt;output&gt;/cpBase dataset will be created.</p>
<p>e.g.: ./submit.sh ta.DistributionComputation spark://localhost:7077 /output/trainingData /output</p>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Telecommunication Analytics</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#peak-detection">Peak Detection</a><ul>
<li><a class="reference internal" href="#data-filter">Data Filter</a><ul>
<li><a class="reference internal" href="#implementation-details">Implementation Details</a></li>
</ul>
</li>
<li><a class="reference internal" href="#distribution-computation">Distribution Computation</a><ul>
<li><a class="reference internal" href="#id1">Implementation Details</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="swan.html" title="previous chapter">Analytics Programming Model - SWAN Compiler</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/telecom_analytics.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Asap consortium.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5a1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/telecom_analytics.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>